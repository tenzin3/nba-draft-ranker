{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "09e1b74a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from scipy.stats import spearmanr, kendalltau  \n",
    "\n",
    "# ----------------------------\n",
    "# 1. Load data\n",
    "# ----------------------------\n",
    "root_dir = Path.cwd().parent.parent\n",
    "dataset_path = root_dir / \"outputs\" / \"college_stats.csv\"\n",
    "\n",
    "df = pd.read_csv(dataset_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1cfd49e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = df[df[\"SEASON\"] != 2025]\n",
    "test_df = df[df[\"SEASON\"] == 2025]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "41ee8da9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------\n",
    "# 2. Simple ranking model\n",
    "# ----------------------------\n",
    "class RankMLP(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim=64):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(input_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: [N, D]\n",
    "        return self.net(x).squeeze(-1)  # [N]\n",
    "\n",
    "# ----------------------------\n",
    "# 3. Listwise losses\n",
    "# ----------------------------\n",
    "\n",
    "def listnet_loss(scores, labels):\n",
    "    \"\"\"\n",
    "    ListNet top-1 cross entropy.\n",
    "    scores: [N] model scores (higher means better)\n",
    "    labels: [N] OVERALL_PICK (lower is better in reality)\n",
    "    We convert labels to relevance by rel = -labels.\n",
    "    \"\"\"\n",
    "    rel = -labels  # larger rel = better\n",
    "    P_y = F.softmax(rel, dim=0)\n",
    "    P_s = F.softmax(scores, dim=0)\n",
    "    loss = -torch.sum(P_y * torch.log(P_s + 1e-12))\n",
    "    return loss\n",
    "\n",
    "def listmle_loss(scores, labels):\n",
    "    \"\"\"\n",
    "    ListMLE loss.\n",
    "    scores: [N]\n",
    "    labels: [N] OVERALL_PICK (lower = better)\n",
    "    We sort items by true ranking (ascending OVERALL_PICK).\n",
    "    \"\"\"\n",
    "    # sort by true rank: best (smallest pick) first\n",
    "    _, idx = torch.sort(labels, descending=False)\n",
    "    s_sorted = scores[idx]\n",
    "\n",
    "    # log-sum-exp over suffixes:\n",
    "    # denominator for position i is sum_{j>=i} exp(s_j)\n",
    "    log_cumsumexp = torch.logcumsumexp(s_sorted.flip(0), dim=0).flip(0)\n",
    "\n",
    "    # log-likelihood: sum_i [s_i - log(sum_{j>=i} exp(s_j))]\n",
    "    log_likelihood = torch.sum(s_sorted - log_cumsumexp)\n",
    "    return -log_likelihood  # negate to get loss\n",
    "\n",
    "# ----------------------------\n",
    "# 4. Evaluation: pairwise ranking accuracy\n",
    "# ----------------------------\n",
    "def pairwise_accuracy(scores, labels):\n",
    "    \"\"\"\n",
    "    Pairwise accuracy within one list.\n",
    "    True order: lower OVERALL_PICK is better.\n",
    "    \"\"\"\n",
    "    scores = scores.detach().cpu().numpy()\n",
    "    labels = labels.detach().cpu().numpy()\n",
    "    n = len(labels)\n",
    "    if n < 2:\n",
    "        return 0.0\n",
    "\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for i in range(n):\n",
    "        for j in range(i + 1, n):\n",
    "            total += 1\n",
    "            true_better = labels[i] < labels[j]  # True if i should rank ahead of j\n",
    "            pred_better = scores[i] > scores[j]  # True if model scores i > j\n",
    "            if (true_better and pred_better) or ((not true_better) and (not pred_better)):\n",
    "                correct += 1\n",
    "    return correct / total if total > 0 else 0.0\n",
    "\n",
    "def evaluate_model(model, groups):\n",
    "    \"\"\"\n",
    "    Evaluate model over all season groups.\n",
    "\n",
    "    Returns a dict with:\n",
    "      - pairwise_accuracy: pooled over all seasons\n",
    "      - spearman: mean Spearman rho across seasons\n",
    "      - kendall:  mean Kendall tau across seasons\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    total_correct = 0.0\n",
    "    total_pairs = 0\n",
    "\n",
    "    spearman_scores = []\n",
    "    kendall_scores = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for season, X, y in groups:\n",
    "            s = model(X)  # scores for this season\n",
    "            n = len(y)\n",
    "            if n < 2:\n",
    "                continue\n",
    "\n",
    "            # ----- pairwise accuracy -----\n",
    "            n_pairs = n * (n - 1) // 2\n",
    "            acc = pairwise_accuracy(s, y)\n",
    "            total_correct += acc * n_pairs\n",
    "            total_pairs += n_pairs\n",
    "\n",
    "            # ----- Spearman & Kendall -----\n",
    "            scores_np = s.detach().cpu().numpy()\n",
    "            labels_np = y.detach().cpu().numpy()\n",
    "\n",
    "            # higher score = better, lower pick = better\n",
    "            # so correlate scores with -labels to make \"better\" = larger value\n",
    "            rho, _ = spearmanr(scores_np, -labels_np)\n",
    "            tau, _ = kendalltau(scores_np, -labels_np)\n",
    "\n",
    "            if not np.isnan(rho):\n",
    "                spearman_scores.append(rho)\n",
    "            if not np.isnan(tau):\n",
    "                kendall_scores.append(tau)\n",
    "\n",
    "    pairwise_acc = total_correct / total_pairs if total_pairs > 0 else 0.0\n",
    "    mean_spearman = float(np.mean(spearman_scores)) if spearman_scores else 0.0\n",
    "    mean_kendall  = float(np.mean(kendall_scores))  if kendall_scores  else 0.0\n",
    "\n",
    "    return {\n",
    "        \"pairwise_accuracy\": pairwise_acc,\n",
    "        \"spearman\":          mean_spearman,\n",
    "        \"kendall\":           mean_kendall,\n",
    "    }\n",
    "\n",
    "# ----------------------------\n",
    "# 5. Training loop helper\n",
    "# ----------------------------\n",
    "def train_listwise(model, groups, loss_fn, n_epochs=200, lr=1e-3, name=\"model\"):\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "    for epoch in range(1, n_epochs + 1):\n",
    "        model.train()\n",
    "        total_loss = 0.0\n",
    "        for season, X, y in groups:\n",
    "            optimizer.zero_grad()\n",
    "            scores = model(X)\n",
    "            loss = loss_fn(scores, y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "        avg_loss = total_loss / max(len(groups), 1)\n",
    "\n",
    "        if epoch % 20 == 0 or epoch == 1:\n",
    "            print(f\"[{name}] Epoch {epoch:3d} | train loss = {avg_loss:.4f}\")\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3e36afba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------\n",
    "# 6. K-fold cross-validation\n",
    "# ----------------------------\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "def prepare_kfold_folds(df, feature_cols, k_folds=5, random_state=42):\n",
    "    \"\"\"\n",
    "    Prepare K-fold season-wise data for listwise ranking.\n",
    "\n",
    "    Returns a list of folds, where each fold is a dict:\n",
    "      {\n",
    "        \"fold_id\": int,\n",
    "        \"train_seasons\": [...],\n",
    "        \"test_seasons\":  [...],\n",
    "        \"train_groups\":  [(season, X, y), ...],\n",
    "        \"test_groups\":   [(season, X, y), ...],\n",
    "      }\n",
    "\n",
    "    Each fold has its own scaling (mean/std) computed from that fold's TRAIN seasons only.\n",
    "    \"\"\"\n",
    "    all_seasons = sorted(df[\"SEASON\"].unique())\n",
    "    kf = KFold(n_splits=k_folds, shuffle=True, random_state=random_state)\n",
    "\n",
    "    folds = []\n",
    "\n",
    "    for fold_id, (train_idx, test_idx) in enumerate(kf.split(all_seasons), start=1):\n",
    "        train_seasons = [all_seasons[i] for i in train_idx]\n",
    "        test_seasons  = [all_seasons[i] for i in test_idx]\n",
    "\n",
    "        df_train = df[df[\"SEASON\"].isin(train_seasons)].copy()\n",
    "        df_test  = df[df[\"SEASON\"].isin(test_seasons)].copy()\n",
    "\n",
    "        # ---- scaling: fit ONLY on this fold's training data ----\n",
    "        train_feats = df_train[feature_cols]\n",
    "        feat_mean = train_feats.mean()\n",
    "        feat_std  = train_feats.std().replace(0, 1.0)\n",
    "\n",
    "        def make_groups(df_subset, seasons_subset):\n",
    "            groups = []\n",
    "            for season in seasons_subset:\n",
    "                g = df_subset[df_subset[\"SEASON\"] == season].copy()\n",
    "                if g.empty:\n",
    "                    continue\n",
    "\n",
    "                g = g.sort_values(\"OVERALL_PICK\")  # lower pick = better\n",
    "                g_scaled = (g[feature_cols] - feat_mean) / feat_std\n",
    "\n",
    "                X = torch.tensor(g_scaled.values, dtype=torch.float32)\n",
    "                y = torch.tensor(g[\"OVERALL_PICK\"].values, dtype=torch.float32)\n",
    "                groups.append((season, X, y))\n",
    "            return groups\n",
    "\n",
    "        train_groups = make_groups(df_train, train_seasons)\n",
    "        test_groups  = make_groups(df_test,  test_seasons)\n",
    "\n",
    "        folds.append({\n",
    "            \"fold_id\": fold_id,\n",
    "            \"train_seasons\": train_seasons,\n",
    "            \"test_seasons\":  test_seasons,\n",
    "            \"train_groups\":  train_groups,\n",
    "            \"test_groups\":   test_groups,\n",
    "        })\n",
    "\n",
    "    return folds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f35b1a6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_cols = [\"player_name\", \"OVERALL_PICK\", \"SEASON\"]\n",
    "feature_cols = [c for c in df.columns if c not in drop_cols]\n",
    "\n",
    "folds = prepare_kfold_folds(\n",
    "    df=train_df,\n",
    "    feature_cols=feature_cols,\n",
    "    k_folds=5,\n",
    "    random_state=42,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3073ca10",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_kfold_for_loss(folds, loss_fn, model_name, n_epochs=200, hidden_dim=64, lr=1e-3):\n",
    "\n",
    "    train_metrics = []\n",
    "    test_metrics  = []\n",
    "\n",
    "    for fold in folds:\n",
    "        fold_id = fold[\"fold_id\"]\n",
    "        train_groups = fold[\"train_groups\"]\n",
    "        test_groups  = fold[\"test_groups\"]\n",
    "\n",
    "        print(f\"\\n===== {model_name} | Fold {fold_id} =====\")\n",
    "        print(\"Train seasons:\", fold[\"train_seasons\"])\n",
    "        print(\"Test  seasons:\", fold[\"test_seasons\"])\n",
    "\n",
    "        torch.manual_seed(42)\n",
    "        model = RankMLP(input_dim=len(feature_cols), hidden_dim=hidden_dim)\n",
    "\n",
    "        model = train_listwise(\n",
    "            model,\n",
    "            train_groups,\n",
    "            loss_fn=loss_fn,\n",
    "            n_epochs=n_epochs,\n",
    "            lr=lr,\n",
    "            name=f\"{model_name} Fold {fold_id}\"\n",
    "        )\n",
    "\n",
    "        # --- NEW: metrics are now dicts ---\n",
    "        train_res = evaluate_model(model, train_groups)\n",
    "        test_res  = evaluate_model(model, test_groups)\n",
    "\n",
    "        train_metrics.append(train_res)\n",
    "        test_metrics.append(test_res)\n",
    "\n",
    "        print(f\"[{model_name} Fold {fold_id}]\")\n",
    "        print(f\"  Train: pairwise={train_res['pairwise_accuracy']:.3f} | \"\n",
    "              f\"Spearman={train_res['spearman']:.3f} | \"\n",
    "              f\"Kendall={train_res['kendall']:.3f}\")\n",
    "        print(f\"  Test : pairwise={test_res['pairwise_accuracy']:.3f} | \"\n",
    "              f\"Spearman={test_res['spearman']:.3f} | \"\n",
    "              f\"Kendall={test_res['kendall']:.3f}\")\n",
    "\n",
    "    # ==== Summary over all folds ====\n",
    "    print(f\"\\n=== {model_name} {len(folds)}-fold CV (season-wise) ===\")\n",
    "\n",
    "    for i, (tr, te) in enumerate(zip(train_metrics, test_metrics), start=1):\n",
    "        print(f\"Fold {i}:\")\n",
    "        print(f\"  Train: pair={tr['pairwise_accuracy']:.3f},  \"\n",
    "              f\"Spearman={tr['spearman']:.3f},  Kendall={tr['kendall']:.3f}\")\n",
    "        print(f\"  Test : pair={te['pairwise_accuracy']:.3f},  \"\n",
    "              f\"Spearman={te['spearman']:.3f},  Kendall={te['kendall']:.3f}\")\n",
    "\n",
    "    # Mean summary\n",
    "    mean_train_pair   = np.mean([m[\"pairwise_accuracy\"] for m in train_metrics])\n",
    "    mean_train_rho    = np.mean([m[\"spearman\"] for m in train_metrics])\n",
    "    mean_train_tau    = np.mean([m[\"kendall\"] for m in train_metrics])\n",
    "\n",
    "    mean_test_pair    = np.mean([m[\"pairwise_accuracy\"] for m in test_metrics])\n",
    "    mean_test_rho     = np.mean([m[\"spearman\"] for m in test_metrics])\n",
    "    mean_test_tau     = np.mean([m[\"kendall\"] for m in test_metrics])\n",
    "\n",
    "    print(\"\\n=== Mean Metrics Across Folds ===\")\n",
    "    print(f\"Train: pair={mean_train_pair:.3f}, Spearman={mean_train_rho:.3f}, Kendall={mean_train_tau:.3f}\")\n",
    "    print(f\"Test : pair={mean_test_pair:.3f}, Spearman={mean_test_rho:.3f}, Kendall={mean_test_tau:.3f}\")\n",
    "\n",
    "    return train_metrics, test_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "74e1eb90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== ListNet | Fold 1 =====\n",
      "Train seasons: [np.int64(2001), np.int64(2002), np.int64(2004), np.int64(2005), np.int64(2006), np.int64(2007), np.int64(2008), np.int64(2010), np.int64(2011), np.int64(2013), np.int64(2014), np.int64(2015), np.int64(2016), np.int64(2018), np.int64(2020), np.int64(2021), np.int64(2022), np.int64(2023), np.int64(2024)]\n",
      "Test  seasons: [np.int64(2000), np.int64(2009), np.int64(2012), np.int64(2017), np.int64(2019)]\n",
      "[ListNet Fold 1] Epoch   1 | train loss = 3.7761\n",
      "[ListNet Fold 1] Epoch  20 | train loss = 2.6211\n",
      "[ListNet Fold 1] Epoch  40 | train loss = 2.3643\n",
      "[ListNet Fold 1] Epoch  60 | train loss = 2.1447\n",
      "[ListNet Fold 1] Epoch  80 | train loss = 1.9611\n",
      "[ListNet Fold 1] Epoch 100 | train loss = 1.8212\n",
      "[ListNet Fold 1] Epoch 120 | train loss = 1.7123\n",
      "[ListNet Fold 1] Epoch 140 | train loss = 1.6177\n",
      "[ListNet Fold 1] Epoch 160 | train loss = 1.5405\n",
      "[ListNet Fold 1] Epoch 180 | train loss = 1.4699\n",
      "[ListNet Fold 1] Epoch 200 | train loss = 1.4045\n",
      "[ListNet Fold 1]\n",
      "  Train: pairwise=0.697 | Spearman=0.545 | Kendall=0.397\n",
      "  Test : pairwise=0.697 | Spearman=0.561 | Kendall=0.392\n",
      "\n",
      "===== ListNet | Fold 2 =====\n",
      "Train seasons: [np.int64(2000), np.int64(2002), np.int64(2004), np.int64(2005), np.int64(2007), np.int64(2008), np.int64(2009), np.int64(2011), np.int64(2012), np.int64(2013), np.int64(2015), np.int64(2016), np.int64(2017), np.int64(2018), np.int64(2019), np.int64(2020), np.int64(2021), np.int64(2023), np.int64(2024)]\n",
      "Test  seasons: [np.int64(2001), np.int64(2006), np.int64(2010), np.int64(2014), np.int64(2022)]\n",
      "[ListNet Fold 2] Epoch   1 | train loss = 3.7524\n",
      "[ListNet Fold 2] Epoch  20 | train loss = 2.3492\n",
      "[ListNet Fold 2] Epoch  40 | train loss = 2.1033\n",
      "[ListNet Fold 2] Epoch  60 | train loss = 1.8981\n",
      "[ListNet Fold 2] Epoch  80 | train loss = 1.7322\n",
      "[ListNet Fold 2] Epoch 100 | train loss = 1.6017\n",
      "[ListNet Fold 2] Epoch 120 | train loss = 1.4993\n",
      "[ListNet Fold 2] Epoch 140 | train loss = 1.4170\n",
      "[ListNet Fold 2] Epoch 160 | train loss = 1.3486\n",
      "[ListNet Fold 2] Epoch 180 | train loss = 1.2907\n",
      "[ListNet Fold 2] Epoch 200 | train loss = 1.2436\n",
      "[ListNet Fold 2]\n",
      "  Train: pairwise=0.682 | Spearman=0.511 | Kendall=0.369\n",
      "  Test : pairwise=0.667 | Spearman=0.446 | Kendall=0.320\n",
      "\n",
      "===== ListNet | Fold 3 =====\n",
      "Train seasons: [np.int64(2000), np.int64(2001), np.int64(2006), np.int64(2007), np.int64(2008), np.int64(2009), np.int64(2010), np.int64(2011), np.int64(2012), np.int64(2014), np.int64(2015), np.int64(2017), np.int64(2018), np.int64(2019), np.int64(2020), np.int64(2021), np.int64(2022), np.int64(2023), np.int64(2024)]\n",
      "Test  seasons: [np.int64(2002), np.int64(2004), np.int64(2005), np.int64(2013), np.int64(2016)]\n",
      "[ListNet Fold 3] Epoch   1 | train loss = 3.8003\n",
      "[ListNet Fold 3] Epoch  20 | train loss = 2.5111\n",
      "[ListNet Fold 3] Epoch  40 | train loss = 2.2176\n",
      "[ListNet Fold 3] Epoch  60 | train loss = 1.9816\n",
      "[ListNet Fold 3] Epoch  80 | train loss = 1.7951\n",
      "[ListNet Fold 3] Epoch 100 | train loss = 1.6564\n",
      "[ListNet Fold 3] Epoch 120 | train loss = 1.5550\n",
      "[ListNet Fold 3] Epoch 140 | train loss = 1.4728\n",
      "[ListNet Fold 3] Epoch 160 | train loss = 1.4017\n",
      "[ListNet Fold 3] Epoch 180 | train loss = 1.3427\n",
      "[ListNet Fold 3] Epoch 200 | train loss = 1.2924\n",
      "[ListNet Fold 3]\n",
      "  Train: pairwise=0.691 | Spearman=0.534 | Kendall=0.384\n",
      "  Test : pairwise=0.661 | Spearman=0.455 | Kendall=0.328\n",
      "\n",
      "===== ListNet | Fold 4 =====\n",
      "Train seasons: [np.int64(2000), np.int64(2001), np.int64(2002), np.int64(2004), np.int64(2005), np.int64(2006), np.int64(2007), np.int64(2009), np.int64(2010), np.int64(2011), np.int64(2012), np.int64(2013), np.int64(2014), np.int64(2015), np.int64(2016), np.int64(2017), np.int64(2019), np.int64(2020), np.int64(2022)]\n",
      "Test  seasons: [np.int64(2008), np.int64(2018), np.int64(2021), np.int64(2023), np.int64(2024)]\n",
      "[ListNet Fold 4] Epoch   1 | train loss = 3.7773\n",
      "[ListNet Fold 4] Epoch  20 | train loss = 2.4304\n",
      "[ListNet Fold 4] Epoch  40 | train loss = 2.1980\n",
      "[ListNet Fold 4] Epoch  60 | train loss = 2.0098\n",
      "[ListNet Fold 4] Epoch  80 | train loss = 1.8686\n",
      "[ListNet Fold 4] Epoch 100 | train loss = 1.7540\n",
      "[ListNet Fold 4] Epoch 120 | train loss = 1.6561\n",
      "[ListNet Fold 4] Epoch 140 | train loss = 1.5746\n",
      "[ListNet Fold 4] Epoch 160 | train loss = 1.5044\n",
      "[ListNet Fold 4] Epoch 180 | train loss = 1.4436\n",
      "[ListNet Fold 4] Epoch 200 | train loss = 1.3914\n",
      "[ListNet Fold 4]\n",
      "  Train: pairwise=0.703 | Spearman=0.559 | Kendall=0.407\n",
      "  Test : pairwise=0.674 | Spearman=0.498 | Kendall=0.353\n",
      "\n",
      "===== ListNet | Fold 5 =====\n",
      "Train seasons: [np.int64(2000), np.int64(2001), np.int64(2002), np.int64(2004), np.int64(2005), np.int64(2006), np.int64(2008), np.int64(2009), np.int64(2010), np.int64(2012), np.int64(2013), np.int64(2014), np.int64(2016), np.int64(2017), np.int64(2018), np.int64(2019), np.int64(2021), np.int64(2022), np.int64(2023), np.int64(2024)]\n",
      "Test  seasons: [np.int64(2007), np.int64(2011), np.int64(2015), np.int64(2020)]\n",
      "[ListNet Fold 5] Epoch   1 | train loss = 3.7166\n",
      "[ListNet Fold 5] Epoch  20 | train loss = 2.2993\n",
      "[ListNet Fold 5] Epoch  40 | train loss = 2.0532\n",
      "[ListNet Fold 5] Epoch  60 | train loss = 1.8297\n",
      "[ListNet Fold 5] Epoch  80 | train loss = 1.6750\n",
      "[ListNet Fold 5] Epoch 100 | train loss = 1.5714\n",
      "[ListNet Fold 5] Epoch 120 | train loss = 1.4942\n",
      "[ListNet Fold 5] Epoch 140 | train loss = 1.4317\n",
      "[ListNet Fold 5] Epoch 160 | train loss = 1.3769\n",
      "[ListNet Fold 5] Epoch 180 | train loss = 1.3292\n",
      "[ListNet Fold 5] Epoch 200 | train loss = 1.2890\n",
      "[ListNet Fold 5]\n",
      "  Train: pairwise=0.675 | Spearman=0.498 | Kendall=0.355\n",
      "  Test : pairwise=0.674 | Spearman=0.490 | Kendall=0.352\n",
      "\n",
      "=== ListNet 5-fold CV (season-wise) ===\n",
      "Fold 1:\n",
      "  Train: pair=0.697,  Spearman=0.545,  Kendall=0.397\n",
      "  Test : pair=0.697,  Spearman=0.561,  Kendall=0.392\n",
      "Fold 2:\n",
      "  Train: pair=0.682,  Spearman=0.511,  Kendall=0.369\n",
      "  Test : pair=0.667,  Spearman=0.446,  Kendall=0.320\n",
      "Fold 3:\n",
      "  Train: pair=0.691,  Spearman=0.534,  Kendall=0.384\n",
      "  Test : pair=0.661,  Spearman=0.455,  Kendall=0.328\n",
      "Fold 4:\n",
      "  Train: pair=0.703,  Spearman=0.559,  Kendall=0.407\n",
      "  Test : pair=0.674,  Spearman=0.498,  Kendall=0.353\n",
      "Fold 5:\n",
      "  Train: pair=0.675,  Spearman=0.498,  Kendall=0.355\n",
      "  Test : pair=0.674,  Spearman=0.490,  Kendall=0.352\n",
      "\n",
      "=== Mean Metrics Across Folds ===\n",
      "Train: pair=0.690, Spearman=0.530, Kendall=0.382\n",
      "Test : pair=0.675, Spearman=0.490, Kendall=0.349\n"
     ]
    }
   ],
   "source": [
    "# ----------------------------\n",
    "# 7. Train and evaluate ListNet\n",
    "# ----------------------------\n",
    "listnet_train_accs, listnet_test_accs = run_kfold_for_loss(\n",
    "    folds=folds,\n",
    "    loss_fn=listnet_loss,\n",
    "    model_name=\"ListNet\",\n",
    "    n_epochs=200,\n",
    "    hidden_dim=64,\n",
    "    lr=1e-3,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dd73e231",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ListNet-Final-AllTrain] Epoch   1 | train loss = 3.7412\n",
      "[ListNet-Final-AllTrain] Epoch  20 | train loss = 2.4562\n",
      "[ListNet-Final-AllTrain] Epoch  40 | train loss = 2.2106\n",
      "[ListNet-Final-AllTrain] Epoch  60 | train loss = 2.0159\n",
      "[ListNet-Final-AllTrain] Epoch  80 | train loss = 1.8539\n",
      "[ListNet-Final-AllTrain] Epoch 100 | train loss = 1.7219\n",
      "[ListNet-Final-AllTrain] Epoch 120 | train loss = 1.6194\n",
      "[ListNet-Final-AllTrain] Epoch 140 | train loss = 1.5370\n",
      "[ListNet-Final-AllTrain] Epoch 160 | train loss = 1.4691\n",
      "[ListNet-Final-AllTrain] Epoch 180 | train loss = 1.4067\n",
      "[ListNet-Final-AllTrain] Epoch 200 | train loss = 1.3516\n",
      "\n",
      "=== Final Model (trained on all seasons except 2025) ===\n",
      "Train (2000–2024): pair=0.692, Spearman=0.534, Kendall=0.386\n",
      "Test  (2025 only): pair=0.715, Spearman=0.631, Kendall=0.433\n"
     ]
    }
   ],
   "source": [
    "# =========================================\n",
    "# 8. Final training on all train seasons\n",
    "#    + evaluation on real test season 2025\n",
    "# =========================================\n",
    "\n",
    "def prepare_holdout_groups(train_df, test_df, feature_cols):\n",
    "    \"\"\"\n",
    "    Build train/test groups for final holdout evaluation.\n",
    "    Scaling is fit on ALL training data (all seasons except 2025),\n",
    "    and applied to both train and test.\n",
    "    \"\"\"\n",
    "    # ---- fit scaler on ALL training rows ----\n",
    "    train_feats = train_df[feature_cols]\n",
    "    feat_mean = train_feats.mean()\n",
    "    feat_std  = train_feats.std().replace(0, 1.0)\n",
    "\n",
    "    def make_groups(df_subset):\n",
    "        groups = []\n",
    "        for season, g in df_subset.groupby(\"SEASON\"):\n",
    "            g = g.sort_values(\"OVERALL_PICK\")  # lower pick = better\n",
    "            g_scaled = (g[feature_cols] - feat_mean) / feat_std\n",
    "\n",
    "            X = torch.tensor(g_scaled.values, dtype=torch.float32)\n",
    "            y = torch.tensor(g[\"OVERALL_PICK\"].values, dtype=torch.float32)\n",
    "            groups.append((season, X, y))\n",
    "        return groups\n",
    "\n",
    "    train_groups = make_groups(train_df)\n",
    "    test_groups  = make_groups(test_df)\n",
    "    return train_groups, test_groups\n",
    "\n",
    "\n",
    "# Build groups for all train seasons (≠ 2025) and the true test season (2025)\n",
    "final_train_groups, final_test_groups = prepare_holdout_groups(\n",
    "    train_df=train_df,\n",
    "    test_df=test_df,\n",
    "    feature_cols=feature_cols,\n",
    ")\n",
    "\n",
    "# Instantiate a fresh model with same hyperparameters as CV\n",
    "torch.manual_seed(42)\n",
    "final_model = RankMLP(input_dim=len(feature_cols), hidden_dim=64)\n",
    "\n",
    "# You can choose ListNet or ListMLE here:\n",
    "final_model = train_listwise(\n",
    "    final_model,\n",
    "    final_train_groups,\n",
    "    loss_fn=listnet_loss,   # or listmle_loss\n",
    "    n_epochs=200,\n",
    "    lr=1e-3,\n",
    "    name=\"ListNet-Final-AllTrain\"\n",
    ")\n",
    "\n",
    "# ---- Evaluate on both train (all past seasons) and test (2025) ----\n",
    "final_train_res = evaluate_model(final_model, final_train_groups)\n",
    "final_test_res  = evaluate_model(final_model, final_test_groups)\n",
    "\n",
    "print(\"\\n=== Final Model (trained on all seasons except 2025) ===\")\n",
    "print(f\"Train (2000–2024): \"\n",
    "      f\"pair={final_train_res['pairwise_accuracy']:.3f}, \"\n",
    "      f\"Spearman={final_train_res['spearman']:.3f}, \"\n",
    "      f\"Kendall={final_train_res['kendall']:.3f}\")\n",
    "\n",
    "print(f\"Test  (2025 only): \"\n",
    "      f\"pair={final_test_res['pairwise_accuracy']:.3f}, \"\n",
    "      f\"Spearman={final_test_res['spearman']:.3f}, \"\n",
    "      f\"Kendall={final_test_res['kendall']:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "35e95dad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== ListMLE | Fold 1 =====\n",
      "Train seasons: [np.int64(2001), np.int64(2002), np.int64(2004), np.int64(2005), np.int64(2006), np.int64(2007), np.int64(2008), np.int64(2010), np.int64(2011), np.int64(2013), np.int64(2014), np.int64(2015), np.int64(2016), np.int64(2018), np.int64(2020), np.int64(2021), np.int64(2022), np.int64(2023), np.int64(2024)]\n",
      "Test  seasons: [np.int64(2000), np.int64(2009), np.int64(2012), np.int64(2017), np.int64(2019)]\n",
      "[ListMLE Fold 1] Epoch   1 | train loss = 138.6040\n",
      "[ListMLE Fold 1] Epoch  20 | train loss = 128.6210\n",
      "[ListMLE Fold 1] Epoch  40 | train loss = 127.1695\n",
      "[ListMLE Fold 1] Epoch  60 | train loss = 126.0747\n",
      "[ListMLE Fold 1] Epoch  80 | train loss = 125.1556\n",
      "[ListMLE Fold 1] Epoch 100 | train loss = 124.3046\n",
      "[ListMLE Fold 1] Epoch 120 | train loss = 123.5974\n",
      "[ListMLE Fold 1] Epoch 140 | train loss = 122.9483\n",
      "[ListMLE Fold 1] Epoch 160 | train loss = 122.2828\n",
      "[ListMLE Fold 1] Epoch 180 | train loss = 121.6443\n",
      "[ListMLE Fold 1] Epoch 200 | train loss = 121.0038\n",
      "[ListMLE Fold 1]\n",
      "  Train: pairwise=0.769 | Spearman=0.717 | Kendall=0.541\n",
      "  Test : pairwise=0.687 | Spearman=0.540 | Kendall=0.382\n",
      "\n",
      "===== ListMLE | Fold 2 =====\n",
      "Train seasons: [np.int64(2000), np.int64(2002), np.int64(2004), np.int64(2005), np.int64(2007), np.int64(2008), np.int64(2009), np.int64(2011), np.int64(2012), np.int64(2013), np.int64(2015), np.int64(2016), np.int64(2017), np.int64(2018), np.int64(2019), np.int64(2020), np.int64(2021), np.int64(2023), np.int64(2024)]\n",
      "Test  seasons: [np.int64(2001), np.int64(2006), np.int64(2010), np.int64(2014), np.int64(2022)]\n",
      "[ListMLE Fold 2] Epoch   1 | train loss = 139.9175\n",
      "[ListMLE Fold 2] Epoch  20 | train loss = 128.8487\n",
      "[ListMLE Fold 2] Epoch  40 | train loss = 127.2944\n",
      "[ListMLE Fold 2] Epoch  60 | train loss = 126.0917\n",
      "[ListMLE Fold 2] Epoch  80 | train loss = 125.1493\n",
      "[ListMLE Fold 2] Epoch 100 | train loss = 124.2689\n",
      "[ListMLE Fold 2] Epoch 120 | train loss = 123.4137\n",
      "[ListMLE Fold 2] Epoch 140 | train loss = 122.5953\n",
      "[ListMLE Fold 2] Epoch 160 | train loss = 121.8423\n",
      "[ListMLE Fold 2] Epoch 180 | train loss = 121.1619\n",
      "[ListMLE Fold 2] Epoch 200 | train loss = 120.5275\n",
      "[ListMLE Fold 2]\n",
      "  Train: pairwise=0.768 | Spearman=0.722 | Kendall=0.543\n",
      "  Test : pairwise=0.679 | Spearman=0.499 | Kendall=0.357\n",
      "\n",
      "===== ListMLE | Fold 3 =====\n",
      "Train seasons: [np.int64(2000), np.int64(2001), np.int64(2006), np.int64(2007), np.int64(2008), np.int64(2009), np.int64(2010), np.int64(2011), np.int64(2012), np.int64(2014), np.int64(2015), np.int64(2017), np.int64(2018), np.int64(2019), np.int64(2020), np.int64(2021), np.int64(2022), np.int64(2023), np.int64(2024)]\n",
      "Test  seasons: [np.int64(2002), np.int64(2004), np.int64(2005), np.int64(2013), np.int64(2016)]\n",
      "[ListMLE Fold 3] Epoch   1 | train loss = 144.6024\n",
      "[ListMLE Fold 3] Epoch  20 | train loss = 133.0181\n",
      "[ListMLE Fold 3] Epoch  40 | train loss = 131.2576\n",
      "[ListMLE Fold 3] Epoch  60 | train loss = 129.9204\n",
      "[ListMLE Fold 3] Epoch  80 | train loss = 128.9500\n",
      "[ListMLE Fold 3] Epoch 100 | train loss = 128.0896\n",
      "[ListMLE Fold 3] Epoch 120 | train loss = 127.2867\n",
      "[ListMLE Fold 3] Epoch 140 | train loss = 126.5150\n",
      "[ListMLE Fold 3] Epoch 160 | train loss = 125.7532\n",
      "[ListMLE Fold 3] Epoch 180 | train loss = 125.0433\n",
      "[ListMLE Fold 3] Epoch 200 | train loss = 124.3669\n",
      "[ListMLE Fold 3]\n",
      "  Train: pairwise=0.773 | Spearman=0.736 | Kendall=0.554\n",
      "  Test : pairwise=0.646 | Spearman=0.431 | Kendall=0.292\n",
      "\n",
      "===== ListMLE | Fold 4 =====\n",
      "Train seasons: [np.int64(2000), np.int64(2001), np.int64(2002), np.int64(2004), np.int64(2005), np.int64(2006), np.int64(2007), np.int64(2009), np.int64(2010), np.int64(2011), np.int64(2012), np.int64(2013), np.int64(2014), np.int64(2015), np.int64(2016), np.int64(2017), np.int64(2019), np.int64(2020), np.int64(2022)]\n",
      "Test  seasons: [np.int64(2008), np.int64(2018), np.int64(2021), np.int64(2023), np.int64(2024)]\n",
      "[ListMLE Fold 4] Epoch   1 | train loss = 137.3084\n",
      "[ListMLE Fold 4] Epoch  20 | train loss = 126.9936\n",
      "[ListMLE Fold 4] Epoch  40 | train loss = 125.5185\n",
      "[ListMLE Fold 4] Epoch  60 | train loss = 124.4713\n",
      "[ListMLE Fold 4] Epoch  80 | train loss = 123.6482\n",
      "[ListMLE Fold 4] Epoch 100 | train loss = 122.9283\n",
      "[ListMLE Fold 4] Epoch 120 | train loss = 122.2639\n",
      "[ListMLE Fold 4] Epoch 140 | train loss = 121.6403\n",
      "[ListMLE Fold 4] Epoch 160 | train loss = 121.0457\n",
      "[ListMLE Fold 4] Epoch 180 | train loss = 120.4479\n",
      "[ListMLE Fold 4] Epoch 200 | train loss = 119.8625\n",
      "[ListMLE Fold 4]\n",
      "  Train: pairwise=0.760 | Spearman=0.707 | Kendall=0.525\n",
      "  Test : pairwise=0.694 | Spearman=0.552 | Kendall=0.394\n",
      "\n",
      "===== ListMLE | Fold 5 =====\n",
      "Train seasons: [np.int64(2000), np.int64(2001), np.int64(2002), np.int64(2004), np.int64(2005), np.int64(2006), np.int64(2008), np.int64(2009), np.int64(2010), np.int64(2012), np.int64(2013), np.int64(2014), np.int64(2016), np.int64(2017), np.int64(2018), np.int64(2019), np.int64(2021), np.int64(2022), np.int64(2023), np.int64(2024)]\n",
      "Test  seasons: [np.int64(2007), np.int64(2011), np.int64(2015), np.int64(2020)]\n",
      "[ListMLE Fold 5] Epoch   1 | train loss = 141.0340\n",
      "[ListMLE Fold 5] Epoch  20 | train loss = 130.6370\n",
      "[ListMLE Fold 5] Epoch  40 | train loss = 129.0904\n",
      "[ListMLE Fold 5] Epoch  60 | train loss = 128.0426\n",
      "[ListMLE Fold 5] Epoch  80 | train loss = 127.2067\n",
      "[ListMLE Fold 5] Epoch 100 | train loss = 126.4548\n",
      "[ListMLE Fold 5] Epoch 120 | train loss = 125.7572\n",
      "[ListMLE Fold 5] Epoch 140 | train loss = 125.1170\n",
      "[ListMLE Fold 5] Epoch 160 | train loss = 124.5098\n",
      "[ListMLE Fold 5] Epoch 180 | train loss = 123.9216\n",
      "[ListMLE Fold 5] Epoch 200 | train loss = 123.3555\n",
      "[ListMLE Fold 5]\n",
      "  Train: pairwise=0.759 | Spearman=0.699 | Kendall=0.522\n",
      "  Test : pairwise=0.701 | Spearman=0.580 | Kendall=0.408\n",
      "\n",
      "=== ListMLE 5-fold CV (season-wise) ===\n",
      "Fold 1:\n",
      "  Train: pair=0.769,  Spearman=0.717,  Kendall=0.541\n",
      "  Test : pair=0.687,  Spearman=0.540,  Kendall=0.382\n",
      "Fold 2:\n",
      "  Train: pair=0.768,  Spearman=0.722,  Kendall=0.543\n",
      "  Test : pair=0.679,  Spearman=0.499,  Kendall=0.357\n",
      "Fold 3:\n",
      "  Train: pair=0.773,  Spearman=0.736,  Kendall=0.554\n",
      "  Test : pair=0.646,  Spearman=0.431,  Kendall=0.292\n",
      "Fold 4:\n",
      "  Train: pair=0.760,  Spearman=0.707,  Kendall=0.525\n",
      "  Test : pair=0.694,  Spearman=0.552,  Kendall=0.394\n",
      "Fold 5:\n",
      "  Train: pair=0.759,  Spearman=0.699,  Kendall=0.522\n",
      "  Test : pair=0.701,  Spearman=0.580,  Kendall=0.408\n",
      "\n",
      "=== Mean Metrics Across Folds ===\n",
      "Train: pair=0.766, Spearman=0.716, Kendall=0.537\n",
      "Test : pair=0.681, Spearman=0.520, Kendall=0.366\n"
     ]
    }
   ],
   "source": [
    "# ----------------------------\n",
    "# 8. Train and evaluate ListMLE\n",
    "# ----------------------------\n",
    "listmle_train_accs, listmle_test_accs = run_kfold_for_loss(\n",
    "    folds=folds,\n",
    "    loss_fn=listmle_loss,\n",
    "    model_name=\"ListMLE\",\n",
    "    n_epochs=200,\n",
    "    hidden_dim=64,\n",
    "    lr=1e-3,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "203bb80d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ListMLE-Final-AllTrain] Epoch   1 | train loss = 139.9994\n",
      "[ListMLE-Final-AllTrain] Epoch  20 | train loss = 129.7068\n",
      "[ListMLE-Final-AllTrain] Epoch  40 | train loss = 128.3372\n",
      "[ListMLE-Final-AllTrain] Epoch  60 | train loss = 127.3779\n",
      "[ListMLE-Final-AllTrain] Epoch  80 | train loss = 126.5796\n",
      "[ListMLE-Final-AllTrain] Epoch 100 | train loss = 125.8577\n",
      "[ListMLE-Final-AllTrain] Epoch 120 | train loss = 125.2207\n",
      "[ListMLE-Final-AllTrain] Epoch 140 | train loss = 124.6199\n",
      "[ListMLE-Final-AllTrain] Epoch 160 | train loss = 124.0712\n",
      "[ListMLE-Final-AllTrain] Epoch 180 | train loss = 123.5496\n",
      "[ListMLE-Final-AllTrain] Epoch 200 | train loss = 123.0214\n",
      "\n",
      "=== Final ListMLE Model (trained on all seasons except 2025) ===\n",
      "Train (2000–2024): pair=0.757, Spearman=0.699, Kendall=0.519\n",
      "Test  (2025 only): pair=0.735, Spearman=0.656, Kendall=0.476\n"
     ]
    }
   ],
   "source": [
    "# =========================================\n",
    "# 9. Final ListMLE: train on all train_df\n",
    "#    and evaluate on real 2025 test_df\n",
    "# =========================================\n",
    "\n",
    "def prepare_holdout_groups(train_df, test_df, feature_cols):\n",
    "    \"\"\"\n",
    "    Build train/test groups for final holdout evaluation.\n",
    "    Scaling is fit on ALL training data (all seasons except 2025),\n",
    "    and applied to both train and test.\n",
    "    \"\"\"\n",
    "    # ---- fit scaler on ALL training rows ----\n",
    "    train_feats = train_df[feature_cols]\n",
    "    feat_mean = train_feats.mean()\n",
    "    feat_std  = train_feats.std().replace(0, 1.0)\n",
    "\n",
    "    def make_groups(df_subset):\n",
    "        groups = []\n",
    "        for season, g in df_subset.groupby(\"SEASON\"):\n",
    "            if g.empty:\n",
    "                continue\n",
    "            g = g.sort_values(\"OVERALL_PICK\")  # lower pick = better\n",
    "            g_scaled = (g[feature_cols] - feat_mean) / feat_std\n",
    "\n",
    "            X = torch.tensor(g_scaled.values, dtype=torch.float32)\n",
    "            y = torch.tensor(g[\"OVERALL_PICK\"].values, dtype=torch.float32)\n",
    "            groups.append((season, X, y))\n",
    "        return groups\n",
    "\n",
    "    train_groups = make_groups(train_df)\n",
    "    test_groups  = make_groups(test_df)\n",
    "    return train_groups, test_groups\n",
    "\n",
    "\n",
    "# Build groups for all train seasons (≠ 2025) and the true test season (2025)\n",
    "final_train_groups_mle, final_test_groups_mle = prepare_holdout_groups(\n",
    "    train_df=train_df,\n",
    "    test_df=test_df,\n",
    "    feature_cols=feature_cols,\n",
    ")\n",
    "\n",
    "# Fresh model for ListMLE final training\n",
    "torch.manual_seed(42)\n",
    "final_model_mle = RankMLP(input_dim=len(feature_cols), hidden_dim=64)\n",
    "\n",
    "# Train with ListMLE loss on ALL past seasons\n",
    "final_model_mle = train_listwise(\n",
    "    final_model_mle,\n",
    "    final_train_groups_mle,\n",
    "    loss_fn=listmle_loss,   # <- key difference\n",
    "    n_epochs=200,\n",
    "    lr=1e-3,\n",
    "    name=\"ListMLE-Final-AllTrain\"\n",
    ")\n",
    "\n",
    "# Evaluate on train (2000–2024) and test (2025)\n",
    "final_train_res_mle = evaluate_model(final_model_mle, final_train_groups_mle)\n",
    "final_test_res_mle  = evaluate_model(final_model_mle, final_test_groups_mle)\n",
    "\n",
    "print(\"\\n=== Final ListMLE Model (trained on all seasons except 2025) ===\")\n",
    "print(f\"Train (2000–2024): \"\n",
    "      f\"pair={final_train_res_mle['pairwise_accuracy']:.3f}, \"\n",
    "      f\"Spearman={final_train_res_mle['spearman']:.3f}, \"\n",
    "      f\"Kendall={final_train_res_mle['kendall']:.3f}\")\n",
    "\n",
    "print(f\"Test  (2025 only): \"\n",
    "      f\"pair={final_test_res_mle['pairwise_accuracy']:.3f}, \"\n",
    "      f\"Spearman={final_test_res_mle['spearman']:.3f}, \"\n",
    "      f\"Kendall={final_test_res_mle['kendall']:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfd7b776",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "82ce6597",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import lightgbm as lgb\n",
    "from scipy.stats import spearmanr, kendalltau\n",
    "\n",
    "\n",
    "def build_lgb_data_for_fold(df, feature_cols, train_seasons, test_seasons):\n",
    "    \"\"\"\n",
    "    Build LightGBM ranking data (X, y, group) for a given fold.\n",
    "    Scaling is fit on TRAIN seasons only.\n",
    "    Returns:\n",
    "      X_train, y_train_rel, group_train,\n",
    "      X_test,  y_test_rel,  group_test,\n",
    "      feat_mean, feat_std\n",
    "    \"\"\"\n",
    "    df_train = df[df[\"SEASON\"].isin(train_seasons)].copy()\n",
    "    df_test  = df[df[\"SEASON\"].isin(test_seasons)].copy()\n",
    "\n",
    "    # ---- scaling (TRAIN only) ----\n",
    "    train_feats = df_train[feature_cols]\n",
    "    feat_mean = train_feats.mean()\n",
    "    feat_std  = train_feats.std().replace(0, 1.0)\n",
    "\n",
    "    def build_X_y_group(df_subset, seasons_subset):\n",
    "        dfs = []\n",
    "        ys = []\n",
    "        group = []\n",
    "        for season in seasons_subset:\n",
    "            g = df_subset[df_subset[\"SEASON\"] == season].copy()\n",
    "            if g.empty:\n",
    "                continue\n",
    "            g = g.sort_values(\"OVERALL_PICK\")  # lower pick = better\n",
    "            dfs.append(g)\n",
    "            ys.append(g[\"OVERALL_PICK\"].values.astype(float))\n",
    "            group.append(len(g))\n",
    "        if not dfs:\n",
    "            return np.empty((0, len(feature_cols))), np.array([]), []\n",
    "        df_cat = pd.concat(dfs, axis=0)\n",
    "        X = ((df_cat[feature_cols] - feat_mean) / feat_std).values\n",
    "        y = np.concatenate(ys, axis=0)\n",
    "        return X, y, group\n",
    "\n",
    "    X_train, y_train, group_train = build_X_y_group(df_train, train_seasons)\n",
    "    X_test,  y_test,  group_test  = build_X_y_group(df_test,  test_seasons)\n",
    "\n",
    "    # LightGBM expects \"higher is better\"\n",
    "    max_y = y_train.max()\n",
    "    y_train_rel = (max_y - y_train).astype(int)   # pick 1 → big number, pick 60 → small number\n",
    "    y_test_rel  = (max_y - y_test).astype(int)\n",
    "\n",
    "    return (\n",
    "        X_train, y_train_rel, group_train,\n",
    "        X_test,  y_test_rel,  group_test,\n",
    "        feat_mean, feat_std,\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0abf0ba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_lambdamart_cv(train_df, feature_cols, k_folds=5, random_state=42, num_boost_round=300):\n",
    "    \"\"\"\n",
    "    LambdaMART (LightGBM lambdarank) with season-wise K-fold CV.\n",
    "    Uses your existing `prepare_kfold_folds` on TRAIN ONLY (no 2025).\n",
    "\n",
    "    Call like:\n",
    "        lgb_cv = run_lambdamart_cv(train_df, feature_cols)\n",
    "\n",
    "    Returns dict of per-fold metrics.\n",
    "    \"\"\"\n",
    "    # folds is built ONLY from train_df (no 2025)\n",
    "    folds = prepare_kfold_folds(train_df, feature_cols, k_folds=k_folds, random_state=random_state)\n",
    "\n",
    "    base_params = {\n",
    "        \"objective\": \"lambdarank\",\n",
    "        \"metric\": \"ndcg\",\n",
    "        \"ndcg_at\": [5, 10, 20],\n",
    "        \"learning_rate\": 0.05,\n",
    "        \"num_leaves\": 31,\n",
    "        \"min_data_in_leaf\": 20,\n",
    "        \"feature_fraction\": 0.8,\n",
    "        \"bagging_fraction\": 0.8,\n",
    "        \"bagging_freq\": 1,\n",
    "        \"max_depth\": -1,\n",
    "        \"verbose\": -1,\n",
    "    }\n",
    "\n",
    "    train_pair_list  = []\n",
    "    test_pair_list   = []\n",
    "    train_spear_list = []\n",
    "    test_spear_list  = []\n",
    "    train_kend_list  = []\n",
    "    test_kend_list   = []\n",
    "\n",
    "    for fold in folds:\n",
    "        fold_id      = fold[\"fold_id\"]\n",
    "        train_seasons = fold[\"train_seasons\"]\n",
    "        test_seasons  = fold[\"test_seasons\"]\n",
    "\n",
    "        print(f\"\\n===== LambdaMART | Fold {fold_id} =====\")\n",
    "        print(\"Train seasons:\", train_seasons)\n",
    "        print(\"Test  seasons:\", test_seasons)\n",
    "\n",
    "        # ---- Build data for this fold (scaling on TRAIN only) ----\n",
    "        (\n",
    "            X_train, y_train_rel, group_train,\n",
    "            X_test,  y_test_rel,  group_test,\n",
    "            feat_mean, feat_std,\n",
    "        ) = build_lgb_data_for_fold(train_df, feature_cols, train_seasons, test_seasons)\n",
    "\n",
    "        if X_train.shape[0] == 0 or X_test.shape[0] == 0:\n",
    "            print(f\"Fold {fold_id}: empty train or test, skipping.\")\n",
    "            continue\n",
    "\n",
    "        max_label = int(max(y_train_rel.max(), y_test_rel.max()))\n",
    "        params = dict(base_params)\n",
    "        params[\"label_gain\"] = list(range(max_label + 1))\n",
    "\n",
    "        train_set = lgb.Dataset(X_train, label=y_train_rel, group=group_train)\n",
    "        valid_set = lgb.Dataset(X_test,  label=y_test_rel,  group=group_test, reference=train_set)\n",
    "\n",
    "        model = lgb.train(\n",
    "            params,\n",
    "            train_set,\n",
    "            num_boost_round=num_boost_round,\n",
    "            valid_sets=[valid_set],\n",
    "            valid_names=[\"valid\"],\n",
    "        )\n",
    "\n",
    "        # ---- Evaluate on TRAIN + TEST seasons for this fold ----\n",
    "        train_pair, train_spear, train_kend = evaluate_lambdamart_fold(\n",
    "            model, train_df, feature_cols, feat_mean, feat_std, train_seasons\n",
    "        )\n",
    "        test_pair, test_spear, test_kend = evaluate_lambdamart_fold(\n",
    "            model, train_df, feature_cols, feat_mean, feat_std, test_seasons\n",
    "        )\n",
    "\n",
    "        print(f\"[Fold {fold_id}]\")\n",
    "        print(f\"  Train: Pairwise = {train_pair:.3f}, Spearman = {train_spear:.3f}, Kendall = {train_kend:.3f}\")\n",
    "        print(f\"  Test : Pairwise = {test_pair:.3f}, Spearman = {test_spear:.3f}, Kendall = {test_kend:.3f}\")\n",
    "\n",
    "        train_pair_list.append(train_pair)\n",
    "        test_pair_list.append(test_pair)\n",
    "        train_spear_list.append(train_spear)\n",
    "        test_spear_list.append(test_spear)\n",
    "        train_kend_list.append(train_kend)\n",
    "        test_kend_list.append(test_kend)\n",
    "\n",
    "    print(\"\\n=== LambdaMART K-fold CV (season-wise) ===\")\n",
    "    for i, (tr_p, te_p, tr_s, te_s, tr_k, te_k) in enumerate(\n",
    "        zip(train_pair_list, test_pair_list,\n",
    "            train_spear_list, test_spear_list,\n",
    "            train_kend_list, test_kend_list),\n",
    "        start=1,\n",
    "    ):\n",
    "        print(f\"Fold {i}: \"\n",
    "              f\"TrainPair = {tr_p:.3f}, TestPair = {te_p:.3f} | \"\n",
    "              f\"TrainSpearman = {tr_s:.3f}, TestSpearman = {te_s:.3f} | \"\n",
    "              f\"TrainKendall = {tr_k:.3f}, TestKendall = {te_k:.3f}\")\n",
    "\n",
    "    print(\"\\nMean Train pairwise:\", np.mean(train_pair_list))\n",
    "    print(\"Mean Test  pairwise:\", np.mean(test_pair_list))\n",
    "    print(\"Mean Train Spearman:\", np.mean(train_spear_list))\n",
    "    print(\"Mean Test  Spearman:\", np.mean(test_spear_list))\n",
    "    print(\"Mean Train Kendall :\", np.mean(train_kend_list))\n",
    "    print(\"Mean Test  Kendall :\", np.mean(test_kend_list))\n",
    "\n",
    "    return {\n",
    "        \"train_pair\":  train_pair_list,\n",
    "        \"test_pair\":   test_pair_list,\n",
    "        \"train_spear\": train_spear_list,\n",
    "        \"test_spear\":  test_spear_list,\n",
    "        \"train_kend\":  train_kend_list,\n",
    "        \"test_kend\":   test_kend_list,\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7b25ac6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_lambdamart_fold(model, df, feature_cols, feat_mean, feat_std, seasons):\n",
    "    \"\"\"\n",
    "    Evaluate LambdaMART model on given seasons:\n",
    "      - pairwise accuracy\n",
    "      - mean Spearman\n",
    "      - mean Kendall\n",
    "    df can be a subset (e.g., train_df or test_df).\n",
    "    \"\"\"\n",
    "    total_correct = 0\n",
    "    total_pairs = 0\n",
    "    spear_list = []\n",
    "    kend_list = []\n",
    "\n",
    "    for s in seasons:\n",
    "        g = df[df[\"SEASON\"] == s].copy()\n",
    "        if g.empty:\n",
    "            continue\n",
    "\n",
    "        g = g.sort_values(\"OVERALL_PICK\")\n",
    "        X = ((g[feature_cols] - feat_mean) / feat_std).values\n",
    "        true_pick = g[\"OVERALL_PICK\"].values.astype(float)\n",
    "\n",
    "        scores = model.predict(X)\n",
    "        n = len(true_pick)\n",
    "\n",
    "        # pairwise accuracy\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        for i in range(n):\n",
    "            for j in range(i + 1, n):\n",
    "                total += 1\n",
    "                true_better = true_pick[i] < true_pick[j]   # smaller pick = better\n",
    "                pred_better = scores[i] > scores[j]         # higher score = better\n",
    "                if true_better == pred_better:\n",
    "                    correct += 1\n",
    "        total_correct += correct\n",
    "        total_pairs += total\n",
    "\n",
    "        # rank correlations (negate picks so higher is better)\n",
    "        spear, _ = spearmanr(-true_pick, scores)\n",
    "        kend, _ = kendalltau(-true_pick, scores)\n",
    "        spear_list.append(spear)\n",
    "        kend_list.append(kend)\n",
    "\n",
    "    pair_acc = total_correct / total_pairs if total_pairs > 0 else 0.0\n",
    "    mean_spear = float(np.nanmean(spear_list)) if spear_list else 0.0\n",
    "    mean_kend  = float(np.nanmean(kend_list))  if kend_list else 0.0\n",
    "\n",
    "    return pair_acc, mean_spear, mean_kend\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0f0d3c89",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_lambdamart_holdout(train_df, test_df, feature_cols, num_boost_round=300):\n",
    "    \"\"\"\n",
    "    Train a final LambdaMART model on ALL training seasons (train_df)\n",
    "    and evaluate on:\n",
    "      - all train seasons (2000–2024)\n",
    "      - hold-out test seasons in test_df (e.g., 2025)\n",
    "    \"\"\"\n",
    "    base_params = {\n",
    "        \"objective\": \"lambdarank\",\n",
    "        \"metric\": \"ndcg\",\n",
    "        \"ndcg_at\": [5, 10, 20],\n",
    "        \"learning_rate\": 0.05,\n",
    "        \"num_leaves\": 31,\n",
    "        \"min_data_in_leaf\": 20,\n",
    "        \"feature_fraction\": 0.8,\n",
    "        \"bagging_fraction\": 0.8,\n",
    "        \"bagging_freq\": 1,\n",
    "        \"max_depth\": -1,\n",
    "        \"verbose\": -1,\n",
    "    }\n",
    "\n",
    "    # ---- scaling on ALL train data ----\n",
    "    feat_mean = train_df[feature_cols].mean()\n",
    "    feat_std  = train_df[feature_cols].std().replace(0, 1.0)\n",
    "\n",
    "    def build_group_from_df(df_slice):\n",
    "        dfs = []\n",
    "        ys = []\n",
    "        groups = []\n",
    "        seasons_list = []\n",
    "        for s, g in df_slice.groupby(\"SEASON\"):\n",
    "            if g.empty:\n",
    "                continue\n",
    "            g = g.sort_values(\"OVERALL_PICK\")\n",
    "            dfs.append(g)\n",
    "            ys.append(g[\"OVERALL_PICK\"].values.astype(float))\n",
    "            groups.append(len(g))\n",
    "            seasons_list.append(s)\n",
    "        if not dfs:\n",
    "            return (\n",
    "                np.empty((0, len(feature_cols))), \n",
    "                np.array([]), \n",
    "                [], \n",
    "                []\n",
    "            )\n",
    "        df_cat = pd.concat(dfs, axis=0)\n",
    "        X = ((df_cat[feature_cols] - feat_mean) / feat_std).values\n",
    "        y = np.concatenate(ys, axis=0)\n",
    "        return X, y, groups, seasons_list\n",
    "\n",
    "    X_train, y_train, group_train, train_seasons = build_group_from_df(train_df)\n",
    "    X_test,  y_test,  group_test,  test_seasons  = build_group_from_df(test_df)\n",
    "\n",
    "    if X_train.shape[0] == 0 or X_test.shape[0] == 0:\n",
    "        raise ValueError(\"Empty train or test data in hold-out training.\")\n",
    "\n",
    "    max_y = y_train.max()\n",
    "    y_train_rel = (max_y - y_train).astype(int)\n",
    "    y_test_rel  = (max_y - y_test).astype(int)\n",
    "\n",
    "    max_label = int(max(y_train_rel.max(), y_test_rel.max()))\n",
    "    params = dict(base_params)\n",
    "    params[\"label_gain\"] = list(range(max_label + 1))\n",
    "\n",
    "    train_set = lgb.Dataset(X_train, label=y_train_rel, group=group_train)\n",
    "    valid_set = lgb.Dataset(X_test,  label=y_test_rel,  group=group_test, reference=train_set)\n",
    "\n",
    "    model = lgb.train(\n",
    "        params,\n",
    "        train_set,\n",
    "        num_boost_round=num_boost_round,\n",
    "        valid_sets=[valid_set],\n",
    "        valid_names=[\"valid\"],\n",
    "    )\n",
    "\n",
    "    # ---- final evaluation ----\n",
    "    train_pair, train_spear, train_kend = evaluate_lambdamart_fold(\n",
    "        model, train_df, feature_cols, feat_mean, feat_std, train_seasons\n",
    "    )\n",
    "    test_pair, test_spear, test_kend = evaluate_lambdamart_fold(\n",
    "        model, test_df, feature_cols, feat_mean, feat_std, test_seasons\n",
    "    )\n",
    "\n",
    "    print(\"\\n=== Final LambdaMART Model (trained on all seasons except 2025) ===\")\n",
    "    print(f\"Train (2000–2024): \"\n",
    "          f\"Pairwise = {train_pair:.3f}, Spearman = {train_spear:.3f}, Kendall = {train_kend:.3f}\")\n",
    "    print(f\"Test  (2025): \"\n",
    "          f\"Pairwise = {test_pair:.3f}, Spearman = {test_spear:.3f}, Kendall = {test_kend:.3f}\")\n",
    "\n",
    "    return {\n",
    "        \"model\": model,\n",
    "        \"feat_mean\": feat_mean,\n",
    "        \"feat_std\": feat_std,\n",
    "        \"train_seasons\": train_seasons,\n",
    "        \"test_seasons\": test_seasons,\n",
    "        \"train_pair\": train_pair,\n",
    "        \"test_pair\": test_pair,\n",
    "        \"train_spear\": train_spear,\n",
    "        \"test_spear\": test_spear,\n",
    "        \"train_kend\": train_kend,\n",
    "        \"test_kend\": test_kend,\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cf22cc3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== LambdaMART | Fold 1 =====\n",
      "Train seasons: [np.int64(2001), np.int64(2002), np.int64(2004), np.int64(2005), np.int64(2006), np.int64(2007), np.int64(2008), np.int64(2010), np.int64(2011), np.int64(2013), np.int64(2014), np.int64(2015), np.int64(2016), np.int64(2018), np.int64(2020), np.int64(2021), np.int64(2022), np.int64(2023), np.int64(2024)]\n",
      "Test  seasons: [np.int64(2000), np.int64(2009), np.int64(2012), np.int64(2017), np.int64(2019)]\n",
      "[Fold 1]\n",
      "  Train: Pairwise = 0.910, Spearman = 0.942, Kendall = 0.826\n",
      "  Test : Pairwise = 0.690, Spearman = 0.550, Kendall = 0.385\n",
      "\n",
      "===== LambdaMART | Fold 2 =====\n",
      "Train seasons: [np.int64(2000), np.int64(2002), np.int64(2004), np.int64(2005), np.int64(2007), np.int64(2008), np.int64(2009), np.int64(2011), np.int64(2012), np.int64(2013), np.int64(2015), np.int64(2016), np.int64(2017), np.int64(2018), np.int64(2019), np.int64(2020), np.int64(2021), np.int64(2023), np.int64(2024)]\n",
      "Test  seasons: [np.int64(2001), np.int64(2006), np.int64(2010), np.int64(2014), np.int64(2022)]\n",
      "[Fold 2]\n",
      "  Train: Pairwise = 0.903, Spearman = 0.937, Kendall = 0.815\n",
      "  Test : Pairwise = 0.671, Spearman = 0.476, Kendall = 0.344\n",
      "\n",
      "===== LambdaMART | Fold 3 =====\n",
      "Train seasons: [np.int64(2000), np.int64(2001), np.int64(2006), np.int64(2007), np.int64(2008), np.int64(2009), np.int64(2010), np.int64(2011), np.int64(2012), np.int64(2014), np.int64(2015), np.int64(2017), np.int64(2018), np.int64(2019), np.int64(2020), np.int64(2021), np.int64(2022), np.int64(2023), np.int64(2024)]\n",
      "Test  seasons: [np.int64(2002), np.int64(2004), np.int64(2005), np.int64(2013), np.int64(2016)]\n",
      "[Fold 3]\n",
      "  Train: Pairwise = 0.903, Spearman = 0.932, Kendall = 0.813\n",
      "  Test : Pairwise = 0.676, Spearman = 0.500, Kendall = 0.352\n",
      "\n",
      "===== LambdaMART | Fold 4 =====\n",
      "Train seasons: [np.int64(2000), np.int64(2001), np.int64(2002), np.int64(2004), np.int64(2005), np.int64(2006), np.int64(2007), np.int64(2009), np.int64(2010), np.int64(2011), np.int64(2012), np.int64(2013), np.int64(2014), np.int64(2015), np.int64(2016), np.int64(2017), np.int64(2019), np.int64(2020), np.int64(2022)]\n",
      "Test  seasons: [np.int64(2008), np.int64(2018), np.int64(2021), np.int64(2023), np.int64(2024)]\n",
      "[Fold 4]\n",
      "  Train: Pairwise = 0.906, Spearman = 0.938, Kendall = 0.822\n",
      "  Test : Pairwise = 0.667, Spearman = 0.485, Kendall = 0.345\n",
      "\n",
      "===== LambdaMART | Fold 5 =====\n",
      "Train seasons: [np.int64(2000), np.int64(2001), np.int64(2002), np.int64(2004), np.int64(2005), np.int64(2006), np.int64(2008), np.int64(2009), np.int64(2010), np.int64(2012), np.int64(2013), np.int64(2014), np.int64(2016), np.int64(2017), np.int64(2018), np.int64(2019), np.int64(2021), np.int64(2022), np.int64(2023), np.int64(2024)]\n",
      "Test  seasons: [np.int64(2007), np.int64(2011), np.int64(2015), np.int64(2020)]\n",
      "[Fold 5]\n",
      "  Train: Pairwise = 0.903, Spearman = 0.936, Kendall = 0.816\n",
      "  Test : Pairwise = 0.699, Spearman = 0.554, Kendall = 0.403\n",
      "\n",
      "=== LambdaMART K-fold CV (season-wise) ===\n",
      "Fold 1: TrainPair = 0.910, TestPair = 0.690 | TrainSpearman = 0.942, TestSpearman = 0.550 | TrainKendall = 0.826, TestKendall = 0.385\n",
      "Fold 2: TrainPair = 0.903, TestPair = 0.671 | TrainSpearman = 0.937, TestSpearman = 0.476 | TrainKendall = 0.815, TestKendall = 0.344\n",
      "Fold 3: TrainPair = 0.903, TestPair = 0.676 | TrainSpearman = 0.932, TestSpearman = 0.500 | TrainKendall = 0.813, TestKendall = 0.352\n",
      "Fold 4: TrainPair = 0.906, TestPair = 0.667 | TrainSpearman = 0.938, TestSpearman = 0.485 | TrainKendall = 0.822, TestKendall = 0.345\n",
      "Fold 5: TrainPair = 0.903, TestPair = 0.699 | TrainSpearman = 0.936, TestSpearman = 0.554 | TrainKendall = 0.816, TestKendall = 0.403\n",
      "\n",
      "Mean Train pairwise: 0.9050501103589934\n",
      "Mean Test  pairwise: 0.6806905955706685\n",
      "Mean Train Spearman: 0.9369085255874362\n",
      "Mean Test  Spearman: 0.5130533865629385\n",
      "Mean Train Kendall : 0.8184280732738836\n",
      "Mean Test  Kendall : 0.3659334982386736\n",
      "\n",
      "=== Final LambdaMART Model (trained on all seasons except 2025) ===\n",
      "Train (2000–2024): Pairwise = 0.902, Spearman = 0.935, Kendall = 0.812\n",
      "Test  (2025): Pairwise = 0.743, Spearman = 0.660, Kendall = 0.489\n"
     ]
    }
   ],
   "source": [
    "# 1. CV on train only (no leakage)\n",
    "lgb_cv = run_lambdamart_cv(train_df, feature_cols, k_folds=5, random_state=42)\n",
    "\n",
    "# 2. Final model on all train seasons, evaluate on 2025\n",
    "lgb_holdout = train_lambdamart_holdout(train_df, test_df, feature_cols)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee7d8d7d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.9.6)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
