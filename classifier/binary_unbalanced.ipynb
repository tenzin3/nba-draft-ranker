{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "76a74d2b",
   "metadata": {},
   "source": [
    "### 1.Create Label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2bc941ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SEASON</th>\n",
       "      <th>OVERALL_PICK</th>\n",
       "      <th>Totals_FG</th>\n",
       "      <th>Totals_FT</th>\n",
       "      <th>Totals_TRB</th>\n",
       "      <th>Totals_BLK</th>\n",
       "      <th>Totals_STL</th>\n",
       "      <th>Totals_TOV</th>\n",
       "      <th>Totals_PF</th>\n",
       "      <th>Shooting_FG%</th>\n",
       "      <th>MP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2000</td>\n",
       "      <td>1</td>\n",
       "      <td>221.0</td>\n",
       "      <td>141.0</td>\n",
       "      <td>300.0</td>\n",
       "      <td>107.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>0.568</td>\n",
       "      <td>909.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2000</td>\n",
       "      <td>2</td>\n",
       "      <td>208.0</td>\n",
       "      <td>127.0</td>\n",
       "      <td>279.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>0.608</td>\n",
       "      <td>1013.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2000</td>\n",
       "      <td>4</td>\n",
       "      <td>327.0</td>\n",
       "      <td>175.0</td>\n",
       "      <td>285.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>0.582</td>\n",
       "      <td>1243.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2000</td>\n",
       "      <td>5</td>\n",
       "      <td>175.0</td>\n",
       "      <td>124.0</td>\n",
       "      <td>243.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>0.476</td>\n",
       "      <td>1058.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2000</td>\n",
       "      <td>6</td>\n",
       "      <td>140.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>123.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>0.478</td>\n",
       "      <td>879.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   SEASON  OVERALL_PICK  Totals_FG  Totals_FT  Totals_TRB  Totals_BLK  \\\n",
       "0    2000             1      221.0      141.0       300.0       107.0   \n",
       "1    2000             2      208.0      127.0       279.0        95.0   \n",
       "2    2000             4      327.0      175.0       285.0        39.0   \n",
       "3    2000             5      175.0      124.0       243.0        15.0   \n",
       "4    2000             6      140.0       70.0       123.0        30.0   \n",
       "\n",
       "   Totals_STL  Totals_TOV  Totals_PF  Shooting_FG%      MP  \n",
       "0        43.0        56.0       71.0         0.568   909.0  \n",
       "1        50.0        80.0       88.0         0.608  1013.0  \n",
       "2        29.0        77.0      103.0         0.582  1243.0  \n",
       "3        46.0        71.0       70.0         0.476  1058.0  \n",
       "4        31.0        46.0       64.0         0.478   879.0  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "current_dir = Path.cwd()\n",
    "df = pd.read_csv(current_dir.parent/ \"data\" /\"cleaned\" / \"college_undrafted.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d7651d96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "drafted\n",
      "1    1210\n",
      "0     559\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# df is your merged dataset\n",
    "# drafted = 1 if picked 1â€“60, undrafted (100) = 0\n",
    "df[\"drafted\"] = (df[\"OVERALL_PICK\"] <= 60).astype(int)\n",
    "print(df[\"drafted\"].value_counts())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcbdb8f2",
   "metadata": {},
   "source": [
    "### 2. Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6bbab986",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: imbalanced-learn in /Users/tenzin/Desktop/mycodes/nba-draft-ranker/.venv/lib/python3.9/site-packages (0.12.4)\n",
      "Requirement already satisfied: numpy>=1.17.3 in /Users/tenzin/Desktop/mycodes/nba-draft-ranker/.venv/lib/python3.9/site-packages (from imbalanced-learn) (2.0.2)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /Users/tenzin/Desktop/mycodes/nba-draft-ranker/.venv/lib/python3.9/site-packages (from imbalanced-learn) (1.5.2)\n",
      "Requirement already satisfied: scipy>=1.5.0 in /Users/tenzin/Desktop/mycodes/nba-draft-ranker/.venv/lib/python3.9/site-packages (from imbalanced-learn) (1.13.1)\n",
      "Requirement already satisfied: scikit-learn>=1.0.2 in /Users/tenzin/Desktop/mycodes/nba-draft-ranker/.venv/lib/python3.9/site-packages (from imbalanced-learn) (1.6.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /Users/tenzin/Desktop/mycodes/nba-draft-ranker/.venv/lib/python3.9/site-packages (from imbalanced-learn) (3.6.0)\n",
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 25.3 is available.\n",
      "You should consider upgrading via the '/Users/tenzin/Desktop/mycodes/nba-draft-ranker/.venv/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install imbalanced-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f1ad06d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train seasons: [np.int64(1952), np.int64(1977), np.int64(1981), np.int64(1986), np.int64(1987), np.int64(1995), np.int64(1999), np.int64(2000), np.int64(2001), np.int64(2002), np.int64(2003), np.int64(2004), np.int64(2005), np.int64(2006), np.int64(2007), np.int64(2008), np.int64(2009), np.int64(2010), np.int64(2011), np.int64(2012), np.int64(2013), np.int64(2014), np.int64(2015), np.int64(2016), np.int64(2017), np.int64(2018), np.int64(2019), np.int64(2020)]\n",
      "Test seasons: [np.int64(2021), np.int64(2022), np.int64(2023), np.int64(2024), np.int64(2025)]\n",
      "Train seasons: [np.int64(1952), np.int64(1977), np.int64(1981), np.int64(1986), np.int64(1987), np.int64(1995), np.int64(1999), np.int64(2000), np.int64(2001), np.int64(2002), np.int64(2003), np.int64(2004), np.int64(2005), np.int64(2006), np.int64(2007), np.int64(2008), np.int64(2009), np.int64(2010), np.int64(2011), np.int64(2012), np.int64(2013), np.int64(2014), np.int64(2015), np.int64(2016), np.int64(2017), np.int64(2018), np.int64(2019), np.int64(2020)]\n",
      "Train size: 1419 Test size: 350\n",
      "Train Class Balance:--->\n",
      "drafted\n",
      "1    938\n",
      "0    481\n",
      "Name: count, dtype: int64\n",
      "Test Class Balance:--->\n",
      "drafted\n",
      "1    272\n",
      "0     78\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "import pandas as pd\n",
    "\n",
    "# ============================\n",
    "# 1. Train/Test Split by SEASON\n",
    "# ============================\n",
    "# Sort all seasons\n",
    "all_seasons = sorted(df[\"SEASON\"].unique())\n",
    "\n",
    "# Number of seasons to use as test (20% of 25 = 5)\n",
    "test_size = 5\n",
    "\n",
    "# Select last 5 seasons\n",
    "test_seasons = all_seasons[-test_size:]\n",
    "\n",
    "# Remaining seasons are the training data\n",
    "train_seasons = all_seasons[:-test_size]\n",
    "\n",
    "print(\"Train seasons:\", train_seasons)\n",
    "print(\"Test seasons:\", test_seasons)\n",
    "\n",
    "# Create train_df and test_df\n",
    "train_df = df[df[\"SEASON\"].isin(train_seasons)].copy()\n",
    "test_df  = df[df[\"SEASON\"].isin(test_seasons)].copy()\n",
    "\n",
    "print(\"Train seasons:\", sorted(train_df[\"SEASON\"].unique()))\n",
    "print(\"Train size:\", len(train_df), \"Test size:\", len(test_df))\n",
    "\n",
    "# ============================\n",
    "# 2. Features / Target\n",
    "# ============================\n",
    "target_col = \"drafted\"   # <-- 1 = drafted, 0 = undrafted\n",
    "\n",
    "feature_cols = [\n",
    "    \"Totals_FG\",\n",
    "    \"Totals_FT\",\n",
    "    \"Totals_TRB\",\n",
    "    \"Totals_STL\",\n",
    "    \"Totals_BLK\",\n",
    "    \"Totals_TOV\",\n",
    "    \"Totals_PF\",\n",
    "    \"Shooting_FG%\",\n",
    "    \"MP\",\n",
    "]\n",
    "\n",
    "X_train = train_df[feature_cols]\n",
    "y_train = train_df[target_col]\n",
    "\n",
    "X_test  = test_df[feature_cols]\n",
    "y_test  = test_df[target_col]\n",
    "\n",
    "print(\"Train Class Balance:--->\")\n",
    "print(y_train.value_counts())\n",
    "\n",
    "print(\"Test Class Balance:--->\")\n",
    "print(y_test.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f81818c",
   "metadata": {},
   "source": [
    "### 3. Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c197282d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class weights (train): {np.int64(0): np.float64(1.475051975051975), np.int64(1): np.float64(0.7563965884861408)}\n",
      "Fold 1: Train AUC=0.975, Val AUC=0.696\n",
      "Fold 2: Train AUC=0.973, Val AUC=0.670\n",
      "Fold 3: Train AUC=0.970, Val AUC=0.649\n",
      "Fold 4: Train AUC=0.973, Val AUC=0.689\n",
      "Fold 5: Train AUC=0.972, Val AUC=0.661\n",
      "\n",
      "===== MEAN TRAIN METRICS (from CV folds) =====\n",
      "Train Accuracy: 0.899\n",
      "Train F1-score: 0.920\n",
      "Train ROC-AUC : 0.973\n",
      "\n",
      "===== MEAN VALIDATION METRICS (from CV folds) =====\n",
      "Validation Accuracy: 0.648\n",
      "Validation F1-score: 0.723\n",
      "Validation ROC-AUC : 0.673\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    f1_score,\n",
    "    roc_auc_score,\n",
    "    confusion_matrix,\n",
    "    classification_report,\n",
    ")\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.base import clone\n",
    "import numpy as np\n",
    "\n",
    "# ============================\n",
    "# 1. Compute class weights from TRAIN\n",
    "# ============================\n",
    "classes = np.array([0, 1])\n",
    "class_weights = compute_class_weight(\n",
    "    class_weight=\"balanced\",\n",
    "    classes=classes,\n",
    "    y=y_train\n",
    ")\n",
    "class_weight_dict = {cls: w for cls, w in zip(classes, class_weights)}\n",
    "print(\"Class weights (train):\", class_weight_dict)\n",
    "\n",
    "# sample_weight vector aligned with y_train index\n",
    "sample_weight_train = np.array([class_weight_dict[c] for c in y_train])\n",
    "\n",
    "# ============================\n",
    "# 2. Base Gradient Boosting model\n",
    "# ============================\n",
    "base_model = GradientBoostingClassifier(\n",
    "    n_estimators=300,\n",
    "    learning_rate=0.05,\n",
    "    max_depth=3,\n",
    "    subsample=0.8,\n",
    "    random_state=42,\n",
    ")\n",
    "\n",
    "# ============================\n",
    "# 3. Manual Stratified K-Fold CV on TRAIN\n",
    "# ============================\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "train_accs, train_f1s, train_aucs = [], [], []\n",
    "val_accs,   val_f1s,   val_aucs   = [], [], []\n",
    "\n",
    "for fold, (tr_idx, val_idx) in enumerate(cv.split(X_train, y_train), start=1):\n",
    "    X_tr, X_val = X_train.iloc[tr_idx], X_train.iloc[val_idx]\n",
    "    y_tr, y_val = y_train.iloc[tr_idx], y_train.iloc[val_idx]\n",
    "    sw_tr = sample_weight_train[tr_idx]\n",
    "\n",
    "    model = clone(base_model)\n",
    "    model.fit(X_tr, y_tr, sample_weight=sw_tr)\n",
    "\n",
    "    # ---- TRAIN metrics ----\n",
    "    y_tr_pred  = model.predict(X_tr)\n",
    "    y_tr_proba = model.predict_proba(X_tr)[:, 1]\n",
    "\n",
    "    train_accs.append(accuracy_score(y_tr, y_tr_pred))\n",
    "    train_f1s.append(f1_score(y_tr, y_tr_pred))\n",
    "    train_aucs.append(roc_auc_score(y_tr, y_tr_proba))\n",
    "\n",
    "    # ---- VALIDATION metrics ----\n",
    "    y_val_pred  = model.predict(X_val)\n",
    "    y_val_proba = model.predict_proba(X_val)[:, 1]\n",
    "\n",
    "    val_accs.append(accuracy_score(y_val, y_val_pred))\n",
    "    val_f1s.append(f1_score(y_val, y_val_pred))\n",
    "    val_aucs.append(roc_auc_score(y_val, y_val_proba))\n",
    "\n",
    "    print(f\"Fold {fold}: Train AUC={train_aucs[-1]:.3f}, Val AUC={val_aucs[-1]:.3f}\")\n",
    "\n",
    "print(\"\\n===== MEAN TRAIN METRICS (from CV folds) =====\")\n",
    "print(f\"Train Accuracy: {np.mean(train_accs):.3f}\")\n",
    "print(f\"Train F1-score: {np.mean(train_f1s):.3f}\")\n",
    "print(f\"Train ROC-AUC : {np.mean(train_aucs):.3f}\")\n",
    "\n",
    "print(\"\\n===== MEAN VALIDATION METRICS (from CV folds) =====\")\n",
    "print(f\"Validation Accuracy: {np.mean(val_accs):.3f}\")\n",
    "print(f\"Validation F1-score: {np.mean(val_f1s):.3f}\")\n",
    "print(f\"Validation ROC-AUC : {np.mean(val_aucs):.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82ec1a6f",
   "metadata": {},
   "source": [
    "### 4.Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9dae3326",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== TEST SET EVALUATION (Last 5 Seasons) =====\n",
      "Confusion matrix on TEST:\n",
      "[[ 39  39]\n",
      " [104 168]]\n",
      "\n",
      "Classification report on TEST:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.273     0.500     0.353        78\n",
      "           1      0.812     0.618     0.701       272\n",
      "\n",
      "    accuracy                          0.591       350\n",
      "   macro avg      0.542     0.559     0.527       350\n",
      "weighted avg      0.692     0.591     0.624       350\n",
      "\n",
      "ROC-AUC on TEST: 0.565\n",
      "F1-score on TEST: 0.701\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ============================\n",
    "# 4. Train on FULL TRAIN and evaluate on TEST\n",
    "# ============================\n",
    "final_model = clone(base_model)\n",
    "final_model.fit(X_train, y_train, sample_weight=sample_weight_train)\n",
    "\n",
    "y_test_pred  = final_model.predict(X_test)               # threshold = 0.5\n",
    "y_test_proba = final_model.predict_proba(X_test)[:, 1]   # probabilities for class 1\n",
    "\n",
    "print(\"\\n===== TEST SET EVALUATION (Last 5 Seasons) =====\")\n",
    "cm = confusion_matrix(y_test, y_test_pred)\n",
    "print(\"Confusion matrix on TEST:\")\n",
    "print(cm)\n",
    "\n",
    "print(\"\\nClassification report on TEST:\")\n",
    "print(classification_report(y_test, y_test_pred, digits=3))\n",
    "\n",
    "test_auc = roc_auc_score(y_test, y_test_proba)\n",
    "test_f1  = f1_score(y_test, y_test_pred)\n",
    "print(f\"ROC-AUC on TEST: {test_auc:.3f}\")\n",
    "print(f\"F1-score on TEST: {test_f1:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ae8039a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
